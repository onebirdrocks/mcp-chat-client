import { NextRequest, NextResponse } from 'next/server';
import { generateText, streamText } from 'ai';
import { serverMCPServerManager } from '@/lib/mcp-manager-server';
import { z } from 'zod';

// å°†JSON Schemaè½¬æ¢ä¸ºzod schemaçš„è¾…åŠ©å‡½æ•°
function jsonSchemaToZod(schema: any): z.ZodType<any> {
  if (schema.type === 'object') {
    const shape: Record<string, z.ZodType<any>> = {};
    
    if (schema.properties) {
      for (const [key, prop] of Object.entries(schema.properties)) {
        const propSchema = prop as any;
        if (propSchema.type === 'string') {
          shape[key] = z.string();
        } else if (propSchema.type === 'integer') {
          shape[key] = z.number().int();
        } else if (propSchema.type === 'number') {
          shape[key] = z.number();
        } else if (propSchema.type === 'boolean') {
          shape[key] = z.boolean();
        } else {
          shape[key] = z.any();
        }
      }
    }
    
    let zodSchema = z.object(shape);
    
    // å¤„ç†requiredå­—æ®µ
    if (schema.required && Array.isArray(schema.required)) {
      for (const requiredField of schema.required) {
        if (shape[requiredField]) {
          // zodå¯¹è±¡é»˜è®¤æ‰€æœ‰å­—æ®µéƒ½æ˜¯å¯é€‰çš„ï¼Œæ‰€ä»¥è¿™é‡Œä¸éœ€è¦ç‰¹æ®Šå¤„ç†
        }
      }
    }
    
    return zodSchema;
  }
  
  return z.any();
}

// è·å–æ¨¡å‹å®ä¾‹
function getModel(providerId: string, modelId: string) {
  const { openai } = require('@ai-sdk/openai');
  const { anthropic } = require('@ai-sdk/anthropic');
  const { google } = require('@ai-sdk/google');
  const { mistral } = require('@ai-sdk/mistral');
  const { cohere } = require('@ai-sdk/cohere');
  const { perplexity } = require('@ai-sdk/perplexity');
  const { fireworks } = require('@ai-sdk/fireworks');
  const { groq } = require('@ai-sdk/groq');
  const { deepseek } = require('@ai-sdk/deepseek');
  const { openrouter } = require('@openrouter/ai-sdk-provider');

  const providers = {
    openai: (modelId: string) => openai(modelId),
    anthropic: (modelId: string) => anthropic(modelId),
    google: (modelId: string) => google(modelId),
    mistral: (modelId: string) => mistral(modelId),
    cohere: (modelId: string) => cohere(modelId),
    perplexity: (modelId: string) => perplexity(modelId),
    fireworks: (modelId: string) => fireworks(modelId),
    groq: (modelId: string) => groq(modelId),
    deepseek: (modelId: string) => deepseek(modelId),
    openrouter: (modelId: string) => openrouter(modelId)
  };

  const provider = providers[providerId as keyof typeof providers];
  return provider ? provider(modelId) : null;
}

export async function POST(request: NextRequest) {
  try {
    const { providerId, modelId, prompt, historyMessages, stream = false } = await request.json();

    if (!providerId || !modelId || !prompt) {
      return NextResponse.json(
        { error: 'Missing required fields: providerId, modelId, prompt' },
        { status: 400 }
      );
    }

    // è·å–æ¨¡å‹å®ä¾‹
    const model = getModel(providerId, modelId);
    if (!model) {
      return NextResponse.json(
        { error: `Model not found: ${providerId}/${modelId}` },
        { status: 404 }
      );
    }

    // è·å–å·¥å…·
    let toolsByServer = serverMCPServerManager.getAllEnabledTools();
    
    // å¦‚æœæ²¡æœ‰å·¥å…·ï¼Œå°è¯•è¿æ¥æ‰€æœ‰æœåŠ¡å™¨
    if (Object.keys(toolsByServer).length === 0) {
      console.log('ğŸ”§ No tools found, attempting to connect all servers...');
      const servers = serverMCPServerManager.getAllServers();
      
      for (const server of servers) {
        try {
          console.log(`ğŸ”§ Attempting to connect to server: ${server.name}`);
          await serverMCPServerManager.connectServer(server.id);
          console.log(`ğŸ”§ Successfully connected to server: ${server.name}`);
        } catch (error) {
          console.error(`ğŸ”§ Failed to connect to server ${server.name}:`, error);
        }
      }
      
      // é‡æ–°è·å–å·¥å…·
      toolsByServer = serverMCPServerManager.getAllEnabledTools();
      console.log('ğŸ”§ Tools after connecting servers:', Object.keys(toolsByServer));
    }
    
    // è½¬æ¢ä¸ºAI SDKæ ¼å¼çš„å·¥å…·
    const toolsToUse: Record<string, any> = {};
    
    for (const [serverName, serverTools] of Object.entries(toolsByServer)) {
      for (const [toolName, toolData] of Object.entries(serverTools)) {
        const functionData = toolData.function;
        
        // ä½¿ç”¨ serverName_toolName ä½œä¸ºå·¥å…·çš„å”¯ä¸€æ ‡è¯†ç¬¦
        const fullToolName = `${serverName}_${toolName}`;
        
        // ä½¿ç”¨ç›´æ¥çš„JSON Schemaå®šä¹‰å·¥å…·
        toolsToUse[fullToolName] = {
          description: functionData.description,
          inputSchema: functionData.parameters, // ç›´æ¥ä½¿ç”¨JSON Schema
          execute: async (args: any) => {
            console.log(`ğŸ”§ Executing tool ${fullToolName} with args:`, args);
            return await serverMCPServerManager.executeTool(fullToolName, args);
          }
        };
      }
    }
    
    console.log('ğŸ”§ Tools converted to AI SDK v5 format:', Object.keys(toolsToUse));
    console.log('ğŸ”§ Using tools count:', Object.keys(toolsToUse).length);
    
    // æ£€æŸ¥å·¥å…·æ ¼å¼æ˜¯å¦æ­£ç¡®
    if (Object.keys(toolsToUse).length > 0) {
      const firstToolName = Object.keys(toolsToUse)[0];
      console.log('ğŸ”§ First tool format:', firstToolName);
      console.log('ğŸ”§ Sample tool structure:', toolsToUse[firstToolName]);
      
      // æ£€æŸ¥æ‰€æœ‰å·¥å…·
      for (const [toolName, toolData] of Object.entries(toolsToUse)) {
        console.log(`ğŸ”§ Tool ${toolName}:`, toolData);
      }
    }
    console.log('ğŸ”§ ==========================================');
    console.log('ğŸ”§ TOOLS DEBUG INFO END');
    console.log('ğŸ”§ ==========================================');

    // æ„å»ºæ¶ˆæ¯æ•°ç»„
    const messages: any[] = [];
    
    if (historyMessages && Array.isArray(historyMessages)) {
      messages.push(...historyMessages);
    }
    
    messages.push({ 
      role: 'user' as const, 
      content: prompt 
    });

    if (stream) {
                        // æµå¼å“åº”
                  console.log('ğŸ”§ Final tools format before AI SDK call (streaming):', Object.keys(toolsToUse));
                  
                  // æ„å»ºè¯·æ±‚ä½“ç”¨äºæ—¥å¿—
                  const requestBody = {
                    model: model.modelId,
                    messages,
                    tools: Object.keys(toolsToUse).length > 0 ? toolsToUse : undefined,
                    temperature: 0.7
                  };
                  
                  console.log('ğŸ”§ Request body to LLM (streaming):', JSON.stringify(requestBody, null, 2));
                  
                  const result = await streamText({
                    model,
                    messages,
                    tools: Object.keys(toolsToUse).length > 0 ? toolsToUse : undefined,
                    temperature: 0.7
                  });
      
      const encoder = new TextEncoder();
      const stream = new ReadableStream({
        async start(controller) {
          try {
            // å¤„ç†æ–‡æœ¬æµ
            for await (const chunk of result.textStream) {
              const data = JSON.stringify({ content: chunk });
              controller.enqueue(encoder.encode(`data: ${data}\n\n`));
            }
            
            // AI-SDKä¼šè‡ªåŠ¨å¤„ç†æœ‰executeå‡½æ•°çš„å·¥å…·è°ƒç”¨
            // ä¸éœ€è¦æ‰‹åŠ¨å¤„ç†å·¥å…·è°ƒç”¨
            
            // å‘é€å®Œæˆä¿¡å·
            controller.enqueue(encoder.encode(`data: [DONE]\n\n`));
            controller.close();
          } catch (error) {
            console.error('Error in stream:', error);
            const errorData = JSON.stringify({ error: error instanceof Error ? error.message : 'Unknown error' });
            controller.enqueue(encoder.encode(`data: ${errorData}\n\n`));
            controller.close();
          }
        }
      });

      return new Response(stream, {
        headers: {
          'Content-Type': 'text/plain; charset=utf-8',
          'Cache-Control': 'no-cache',
          'Connection': 'keep-alive',
        },
      });
    } else {
      // éæµå¼å“åº” - ä½¿ç”¨streamTextç„¶åæ”¶é›†ç»“æœ
      console.log('ğŸ”§ About to call streamText with tools:', Object.keys(toolsToUse));
      
                        // ä½¿ç”¨å·¥å…·è°ƒç”¨
                  console.log('ğŸ”§ Final tools format before AI SDK call:', Object.keys(toolsToUse));
                  
                  // æ„å»ºè¯·æ±‚ä½“ç”¨äºæ—¥å¿—
                  const requestBody = {
                    model: model.modelId,
                    messages,
                    tools: Object.keys(toolsToUse).length > 0 ? toolsToUse : undefined,
                    temperature: 0.7
                  };
                  
                  console.log('ğŸ”§ Request body to LLM (non-streaming):', JSON.stringify(requestBody, null, 2));
                  
                  const result = await streamText({
                    model,
                    messages,
                    tools: Object.keys(toolsToUse).length > 0 ? toolsToUse : undefined,
                    temperature: 0.7
                  });
      
      // æ”¶é›†æ–‡æœ¬å†…å®¹
      let textContent = '';
      for await (const chunk of result.textStream) {
        textContent += chunk;
      }
      
      // AI-SDKä¼šè‡ªåŠ¨å¤„ç†å·¥å…·è°ƒç”¨ï¼Œç›´æ¥è¿”å›æ–‡æœ¬å†…å®¹
      return NextResponse.json({
        success: true,
        result: {
          text: textContent,
          toolCalls: [],
          toolResults: []
        }
      });
    }

  } catch (error) {
    console.error('Error in simplified AI SDK tool call:', error);
    return NextResponse.json(
      { error: error instanceof Error ? error.message : 'Unknown error' },
      { status: 500 }
    );
  }
}
